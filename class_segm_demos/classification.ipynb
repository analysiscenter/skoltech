{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Data](#Data)\n",
    "* [Pipeline](#Pipeline)\n",
    "* [Setting Model](#Model-definition)\n",
    "* [Training](#Training)\n",
    "* [Validation](#Validation)\n",
    "* [AlexNet](#AlexNet)\n",
    "* [VGG](#VGG)\n",
    "* [ResNet](#ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow.opensets import CIFAR10, CIFAR100, Imagenette160, ImageWoof, PascalClassification, MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Imagenette160()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats what happening under the hood the line above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from batchflow import Dataset, DatasetIndex, ImagesBatch\n",
    "# my_index = DatasetIndex(np.arange(len(imagenette_data)))\n",
    "# data = Dataset(my_index, \n",
    "#                batch_class=ImagesBatch, \n",
    "#                preloaded=imagenette_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset divided into train and test parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Images in train: {}'.format(len(data.train.images)))\n",
    "print('Images in test: {}'.format(len(data.test.images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['tench', 'English springer', 'cassette player', 'chain saw', 'church',\n",
    "           'French horn', 'garbage truck', 'gas pump', 'golf ball', 'parachute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(len(data.train), size=10)\n",
    "images = data.train.images[ind]\n",
    "labels = data.train.labels[ind]\n",
    "images = np.array(images)\n",
    "plot_images(images, labels=labels, classes=classes, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare pipeline with augmentations.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (data.train.pipeline()\n",
    "               .crop(shape=(160, 160), origin='random', dst='augm_images')\n",
    "               .flip(p=0.5, src='augm_images', dst='augm_images')\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look the all images actions avaliable. [link](https://github.com/analysiscenter/batchflow/blob/master/examples/tutorials/06_image_augmentation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImagesBatch:\n",
    "#     def flip(self):\n",
    "#         # code for flipping images\n",
    "#         return self\n",
    "    \n",
    "#     def rotate(self):\n",
    "#         # code for rotation images\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = pipeline.next_batch(batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch)):\n",
    "    fig, ax = plt.subplots(1, 2 , figsize=(10, 3))\n",
    "    ax[0].imshow(batch.images[i])\n",
    "    ax[1].imshow(batch.augm_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow.models.torch import TorchModel\n",
    "from batchflow import B, V, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "#          'initial_block': empty\n",
    "           'body/layout': 'ca ca',\n",
    "           'body/filters': [5, 10],\n",
    "           'head/layout': 'f',\n",
    "           'head/units': 10,\n",
    "    \n",
    "           'output': {'predicted': ['proba']},    \n",
    "           'loss': 'ce',\n",
    "           'optimizer': dict(name='SGD', lr=0.01),\n",
    "           'device': 'gpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_ITERS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (data.train.p \n",
    "                    .crop(shape=(160, 160), origin='random')\n",
    "                    .flip(p=0.5)\n",
    "                    .to_array(channels='first') \n",
    "                    .init_variable('loss', []) \n",
    "                    .init_model('dynamic', TorchModel, 'classification', model_config)\n",
    "                    .train_model('classification', B('images'), B('labels'), \n",
    "                                 fetches='loss', save_to=V('loss', mode='a'))\n",
    "                    .run_later(BATCH_SIZE, n_iters=N_ITERS, drop_last=True, shuffle=42, bar=True)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.run(bar_desc=W(V('loss')[-1].format('Loss is: {:7.7}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = train_pipeline.v('loss')\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(loss[5:])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = (data.test.p\n",
    "                    .crop(shape=(160, 160), origin='random')\n",
    "                    .to_array(channels='first')\n",
    "                    .import_model('classification', train_pipeline)\n",
    "                    .init_variable('metrics')\n",
    "                    .predict_model('classification', B('images'), fetches='predicted_proba', \n",
    "                                   save_to=B('predictions'))\n",
    "                    .gather_metrics('class', targets=B.labels, predictions=B.predictions,\n",
    "                                    fmt='proba', axis=-1, save_to=V('metrics'))\n",
    "                    .run_later(100, shuffle=True, n_epochs=1, drop_last=False, bar=True)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = test_pipeline.v('metrics')\n",
    "accuracy = metrics.evaluate('accuracy')\n",
    "print('Accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw images from test data and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_pipeline.next_batch(10, shuffle=True)\n",
    "\n",
    "images = np.moveaxis(batch.images, 1, -1)\n",
    "plot_images(images, labels=batch.labels, proba=batch.predictions, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow import C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (data.train.p \n",
    "                    .crop(shape=(160, 160), origin='random')\n",
    "                    .flip(p=0.5)\n",
    "                    .to_array(channels='first') \n",
    "                    .init_variable('loss', []) \n",
    "                    .init_model('dynamic', C('model_class'), 'classification', C('model'))\n",
    "                    .train_model('classification', B('images'), B('labels'), \n",
    "                                 fetches='loss', save_to=V('loss', mode='a'))\n",
    "                    .run_later(C('batch_size'), n_iters=C('n_iters'), drop_last=True, shuffle=42, bar=True)\n",
    "                )\n",
    "\n",
    "test_pipeline = (data.test.p\n",
    "                    .crop(shape=(160, 160), origin='random')\n",
    "                    .to_array(channels='first')\n",
    "                    .init_variable('metrics')\n",
    "                    .import_model('classification', C('train_ppl'))\n",
    "                    .predict_model('classification', B('images'), fetches='predicted_proba', \n",
    "                                   save_to=B('predictions'))\n",
    "                    .gather_metrics('class', targets=B.labels, predictions=B.predictions,\n",
    "                                    fmt='proba', axis=-1, save_to=V('metrics'))\n",
    "                    .run_later(300, shuffle=True, n_epochs=1, drop_last=False, bar=True)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model = {\n",
    "    'initial_block': {'layout': 'cap', 'kernel_size': 11, 'filters': 4, 'strides': 4, 'pool_size': 3},\n",
    "    'body': {'layout': 'cap ca ca ca', 'kernel_size': [5, 3, 3, 3], 'filters': [8, 16, 32, 64]},\n",
    "    'head': {'layout': 'fa f', 'units': [100, 10]},\n",
    "       \n",
    "    'optimizer': dict(name='SGD', lr=10),    \n",
    "    'output': {'predicted': ['proba']},    \n",
    "    'loss': 'ce',\n",
    "    'optimizer': dict(name='SGD', lr=0.1),\n",
    "    'device': 'gpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "        'model': alexnet_model,\n",
    "        'model_class': TorchModel,\n",
    "        'batch_size': 64,\n",
    "        'n_iters': 300\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_train = train_pipeline << train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_train.run(bar_desc=W(V('loss')[-1].format('Loss is: {:7.7}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = alexnet_train.v('loss')\n",
    "plt.plot(loss[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    'train_ppl': alexnet_train,\n",
    "#    'metrics_name': 'alex_metr'\n",
    "}\n",
    "\n",
    "alexnet_test = test_pipeline << test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = alexnet_test.v('metrics')\n",
    "accuracy = metrics.evaluate('accuracy')\n",
    "print('Accuracy AlexNet - {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_common = {\n",
    "    'device': 'gpu',\n",
    "    'loss': 'ce',\n",
    "    'output': {'predicted': ['proba']},    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = {\n",
    "    'body': dict(layout='ca ca p' * 5, kernel_size=3, \n",
    "                 filters=[8, 8, 16, 16, 32, 32,  64, 64, 128, 128]),\n",
    "    'head': dict(layout='fa f', units=[100, 10]),\n",
    "    \n",
    "    'optimizer': dict(name='Adam', lr=0.001),    \n",
    "    **model_common\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "        'model': vgg_model,\n",
    "        'model_class': TorchModel,\n",
    "        'batch_size': 64,\n",
    "        'n_iters': 500\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train = train_pipeline << train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train.run(bar_desc=W(V('loss')[-1].format('Loss is: {:7.7}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = vgg_train.v('loss')\n",
    "plt.plot(loss[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    'train_ppl': vgg_train,\n",
    "#    'metrics_name': 'vgg_metr' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_test = test_pipeline << test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = vgg_test.v('metrics')\n",
    "accuracy = metrics.evaluate('accuracy')\n",
    "print('Accuracy VGG - {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = vgg_test.next_batch(5, shuffle=True)\n",
    "\n",
    "images = np.moveaxis(batch.images, 1, -1)\n",
    "plot_images(images, labels=batch.labels, proba=batch.predictions, classes=classes, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can import and train ready to use model from [model's zoo](https://analysiscenter.github.io/batchflow/api/batchflow.models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from batchflow.models.torch import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_config = {\n",
    "#            'initial_block':dict(layout='cnap', filters=8, kernel_size=7, strides=2,\n",
    "#                                 pool_size=3, pool_strides=2),\n",
    "#            'body': {'layout': 'R cnacna+ R cnacna+ p R cnacna& R cnacna+ p R cnacna& R cnacna+ p R cnacna& R cnacna+',\n",
    "#                     'filters': [8, 8, 8, 8, 16, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 64]},\n",
    "#            'head': dict(layout='cV', filters=10),\n",
    "    \n",
    "#            'optimizer': dict(name='Adam', lr=0.001),\n",
    "#             **model_common\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow.models.torch import Encoder\n",
    "from batchflow.models.torch import ResBlock, VGGBlock, DenseBlock, XceptionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_config = {\n",
    "           'initial_block':dict(layout='cnap', filters=8, kernel_size=7, strides=2,\n",
    "                                pool_size=3, pool_strides=2),   \n",
    "           'body/encoder/num_stages': 4,\n",
    "           'body/encoder/blocks': dict(base=ResBlock, layout='cnacna',\n",
    "                                              filters=[8, 16, 32, 64],\n",
    "                                              n_reps=[2, 2, 2, 2],\n",
    "                                              downsample=[False, True, True, True]),\n",
    "           'head': dict(layout='cV', filters=10),\n",
    "    \n",
    "           'optimizer': dict(name='Adam', lr=0.001),\n",
    "            **model_common\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "        'model': resnet_config,\n",
    "        'model_class': Encoder,\n",
    "        'batch_size': 64,\n",
    "        'n_iters': 1000\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_train = train_pipeline << train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_train.run(bar_desc=W(V('loss')[-1].format('Loss is: {:7.7}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from batchflow.models.torch import ResNet34\n",
    "# resnet_config = {\n",
    "#            'head': dict(layout='cV', filters=10),\n",
    "    \n",
    "#            'optimizer': dict(name='Adam', lr=0.001),\n",
    "#             **model_common\n",
    "#         }\n",
    "\n",
    "# train_config = {\n",
    "#         'model': resnet_config,\n",
    "#         'model_class': ResNet34,\n",
    "#         'batch_size': 64,\n",
    "#         'n_iters': 1000\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = resnet_train.v('loss')\n",
    "plt.plot(loss[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    'train_ppl': resnet_train\n",
    "}\n",
    "\n",
    "resnet_test = test_pipeline << test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = resnet_test.v('metrics')\n",
    "metrics.evaluate('accuracy')\n",
    "print('Accuracy ResNet - {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = resnet_test.next_batch(10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.moveaxis(batch.images, 1, -1)\n",
    "plot_images(images, labels=batch.labels, proba=batch.predictions, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
