{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../..')\n",
    "from batchflow import B, V, F, R, P, W\n",
    "from batchflow.opensets import PascalSegmentation\n",
    "from batchflow.models.torch import TorchModel, UNet\n",
    "from batchflow.models.metrics import ClassificationMetrics\n",
    "\n",
    "from utils import segmentation_plot\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data. May take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PascalSegmentation(bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Images in train: {}'.format(len(data.train)))\n",
    "print('Images in test: {}'.format(len(data.test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = (i for i in range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = next(gen)\n",
    "segmentation_plot((data.train.images[i]), data.train.labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 22\n",
    "model_config = {\n",
    "                'body/encoder/num_stages': 4,\n",
    "                'body/decoder/blocks/filters': [128, 64, 64, 32],\n",
    "                'body/encoder/blocks/filters': [32, 64, 64, 128],\n",
    "                'body/embedding/filters': 128,\n",
    "                'head': dict(layout='c', filters=NUM_CLASSES, kernel_size=1),\n",
    "    \n",
    "                'optimizer': ('Adam', {'lr': 0.001}),\n",
    "                'device': 'gpu',\n",
    "                'loss': 'ce'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mask(x):\n",
    "    x = np.squeeze(x)\n",
    "    np.place(x, x==255, 21)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (160, 160)\n",
    "pipeline = (data.train.p\n",
    "                 .init_model('dynamic', UNet, 'segm', config=model_config)   #initialize model\n",
    "                 .resize(size=size, src='images', dst='images')              # resize image\n",
    "                 .resize(size=size, src='labels', dst='labels')              # resize mask\n",
    "                 .init_variable('loss', [])                                  # save the loss here\n",
    "                 .to_array(channels='first')                                 # convert the image from PIL to np.array with channels  as first dimension\n",
    "                 .to_array(channels='first', src='labels', dst='labels')     # same for mask\n",
    "                 .apply_transform_all(src='labels', dst='labels', func=process_mask)  #  replace 255 ->>> 21\n",
    "                 .train_model('segm', B('images'), B('labels'), fetches='loss', save_to=V('loss', mode='a')) # train the model\n",
    "                 .run_later(BATCH_SIZE, n_epochs=N_EPOCHS, drop_last=True, shuffle=42, bar=True)                \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run(bar_desc=W(V('loss')[-1].format('Loss is: {:7.7}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pipeline.v('loss')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = (data.test.p\n",
    "                    .import_model('segm', pipeline)\n",
    "                    .resize(size=size, src='images', dst='images')\n",
    "                    .resize(size=size, src='labels', dst='labels')\n",
    "                    .init_variable('predictions')\n",
    "                    .to_array(channels='first')\n",
    "                    .to_array(channels='first', src='labels', dst='labels')\n",
    "                    .apply_transform_all(src='labels', dst='labels', func=process_mask)\n",
    "                    .predict_model('segm', B('images'), fetches='predictions', save_to=B('predictions'))\n",
    "                )                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_pipeline.next_batch(5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow.models.metrics import SegmentationMetricsByPixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = SegmentationMetricsByPixels(batch.labels, batch.predictions, axis=-1, \n",
    "                                      fmt='logits', num_classes=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.evaluate(['iou', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "    image = np.moveaxis(batch.images[i], 0, -1)\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].imshow(batch.labels[i])\n",
    "    ax[2].imshow(np.argmax(batch.predictions[i], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
